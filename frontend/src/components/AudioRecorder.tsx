import { useState, useRef, useEffect, useCallback } from 'react';
import { useMeetingStore } from '../stores/meetingStore';

interface AudioRecorderProps {
  onAudioChunk: (blob: Blob) => void;
}

export function AudioRecorder({ onAudioChunk }: AudioRecorderProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const chunksRef = useRef<Blob[]>([]);
  const intervalRef = useRef<number | null>(null);
  const lastSentIndexRef = useRef<number>(0);

  const { setRecording } = useMeetingStore();

  // ëˆ„ì ëœ ì˜¤ë””ì˜¤ë¥¼ ì „ì†¡í•˜ëŠ” í•¨ìˆ˜
  const sendAccumulatedAudio = useCallback(() => {
    if (chunksRef.current.length > lastSentIndexRef.current) {
      // ëª¨ë“  chunkë¥¼ í•©ì³ì„œ í•˜ë‚˜ì˜ blobìœ¼ë¡œ ë§Œë“¦
      const allChunks = chunksRef.current.slice(0, chunksRef.current.length);
      const audioBlob = new Blob(allChunks, { type: 'audio/webm' });

      if (audioBlob.size > 1000) { // ìµœì†Œ 1KB ì´ìƒë§Œ ì „ì†¡
        console.log(`Sending accumulated audio: ${audioBlob.size} bytes (${allChunks.length} chunks)`);
        onAudioChunk(audioBlob);
        lastSentIndexRef.current = chunksRef.current.length;
      }
    }
  }, [onAudioChunk]);

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;
      chunksRef.current = [];
      lastSentIndexRef.current = 0;

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm'
      });

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          chunksRef.current.push(e.data);
        }
      };

      mediaRecorder.onerror = (e) => {
        console.error('MediaRecorder error:', e);
        setError('ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
      };

      // 1ì´ˆë§ˆë‹¤ ë°ì´í„° ìˆ˜ì§‘ (ì‘ì€ chunkë¡œ)
      mediaRecorder.start(1000);
      mediaRecorderRef.current = mediaRecorder;

      // 5ì´ˆë§ˆë‹¤ ëˆ„ì ëœ ì˜¤ë””ì˜¤ ì „ì†¡
      intervalRef.current = window.setInterval(() => {
        sendAccumulatedAudio();
      }, 5000);

      setIsRecording(true);
      setRecording(true);
      setError(null);

    } catch (err) {
      console.error('Failed to start recording:', err);
      setError('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
    }
  };

  const stopRecording = () => {
    if (intervalRef.current) {
      clearInterval(intervalRef.current);
      intervalRef.current = null;
    }

    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }

    // ë§ˆì§€ë§‰ ë‚¨ì€ ì˜¤ë””ì˜¤ ì „ì†¡
    sendAccumulatedAudio();

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
    }

    chunksRef.current = [];
    lastSentIndexRef.current = 0;
    setIsRecording(false);
    setRecording(false);
  };

  useEffect(() => {
    return () => {
      // Cleanup on unmount
      if (intervalRef.current) {
        clearInterval(intervalRef.current);
      }
      if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
        mediaRecorderRef.current.stop();
      }
      if (streamRef.current) {
        streamRef.current.getTracks().forEach(track => track.stop());
      }
    };
  }, []);

  return (
    <div className="audio-recorder">
      <button
        onClick={isRecording ? stopRecording : startRecording}
        className={`record-button ${isRecording ? 'recording' : ''}`}
      >
        {isRecording ? 'â¹ï¸ ì •ì§€' : 'ğŸ¤ ë…¹ìŒ ì‹œì‘'}
      </button>

      {isRecording && (
        <div className="recording-indicator">
          <span className="pulse"></span>
          ë…¹ìŒ ì¤‘...
        </div>
      )}

      {error && (
        <div className="error-message">
          âš ï¸ {error}
        </div>
      )}
    </div>
  );
}

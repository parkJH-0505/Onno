# Onno í”„ë¡œí† íƒ€ì… ê°œë°œ TODO

**ìµœì¢… ì—…ë°ì´íŠ¸**: 2025-12-02
**í˜„ì¬ ë‹¨ê³„**: Phase 0 ì™„ë£Œ âœ… â†’ Phase 1 í”„ë¡œí† íƒ€ì… ê°œë°œ

---

## ğŸ“Š í”„ë¡œì íŠ¸ ì§„í–‰ í˜„í™©

### âœ… ì™„ë£Œëœ ì‘ì—… (Phase 0: ì „ëµ & ì„¤ê³„)

```
ì „ëµ ìˆ˜ë¦½ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% âœ…
ì œí’ˆ ê¸°íš â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% âœ…
ì•„í‚¤í…ì²˜ ì„¤ê³„ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% âœ…
ì¸í”„ë¼ ì„¤ê³„ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% âœ…
í”„ë¡œí† íƒ€ì… ê°œë°œ â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘   0%
```

---

## ğŸ“ ì™„ë£Œëœ Phase 0 ì‘ì—… ìš”ì•½

### âœ… 15ê°œ ë¬¸ì„œ ì‘ì„± ì™„ë£Œ (~15,000ì¤„)

1. **PRD 4ë¶€ì‘** - ì „ëµ, ê¸°ëŠ¥ëª…ì„¸, ê¸°ìˆ ì•„í‚¤í…ì²˜, ë§ˆìŠ¤í„°í”Œëœ
2. **ê°œì¸í™” ì‹œìŠ¤í…œ** - "ë‚˜ë§Œì˜ ì˜¨ë…¸" (Lv.1-5, í˜ë¥´ì†Œë‚˜ 4ê°œ)
3. **ê´€ê³„ ê°ì²´ ì‹œìŠ¤í…œ** - ê±°ë˜ì²˜ë³„ ì»¨í…ìŠ¤íŠ¸ ì €ì¥ì†Œ
4. **ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜** (~3,000ì¤„) - Frontend, Backend, AI/ML Pipeline
5. **ì¸í”„ë¼ ì•„í‚¤í…ì²˜** (~2,200ì¤„) - AWS 17ê°œ ì„œë¹„ìŠ¤, VPC ì„¤ê³„, CI/CD
6. **í”„ë¡œì íŠ¸ ê°€ì´ë“œ** - Quick Start, FAQ, ì˜¨ë³´ë”©

### âœ… í•µì‹¬ ê¸°ìˆ  ê²°ì •

- **STT**: OpenAI Whisper API
- **LLM**: GPT-4o (ì§ˆë¬¸ ìƒì„±)
- **Frontend**: React 18 + TypeScript + Vite + Zustand
- **Backend**: Node.js + Express + Prisma + Socket.io
- **AI/ML**: Python FastAPI
- **Infra**: AWS ECS Fargate, RDS PostgreSQL, ElastiCache Redis, S3
- **Vector DB**: Pinecone

### âœ… í•µì‹¬ ì°¨ë³„ì  ì •ì˜

1. **During-the-fact** (ì‹¤ì‹œê°„ ë¶„ì„) vs After-the-fact
2. **ê°œì¸í™” ì‹œìŠ¤í…œ** (ì‚¬ìš©í• ìˆ˜ë¡ ë‚˜ë§Œì˜ ì˜¨ë…¸ë¡œ ì„±ì¥)
3. **Vertical AI** (VC/AC ì „ë¬¸ ë„ë©”ì¸ íŠ¹í™”)
4. **ê´€ê³„ ê°ì²´** (ê±°ë˜ì²˜ë³„ ì»¨í…ìŠ¤íŠ¸ ìë™ ë¡œë“œ)

---

## ğŸ¯ Phase 1: í”„ë¡œí† íƒ€ì… ê°œë°œ ê³„íš

**ëª©í‘œ**: ì‹œìŠ¤í…œ ì„¤ê³„ë¥¼ ê²€ì¦í•˜ê³  í•µì‹¬ ë°ì´í„° íë¦„ê³¼ ì‚¬ìš©ì ì¸í„°ë™ì…˜ì„ í”„ë¡œí† íƒ€ì…ìœ¼ë¡œ êµ¬í˜„

---

### ğŸ“… Step 1: ê°œë°œ í™˜ê²½ êµ¬ì¶• (1-2ì¼)

#### 1-1. í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±

- [ ] **Frontend í”„ë¡œì íŠ¸ ì´ˆê¸°í™”**
  ```bash
  npm create vite@latest onno-frontend -- --template react-ts
  cd onno-frontend
  npm install
  npm install zustand socket.io-client
  npm install -D @types/node
  ```

  ë””ë ‰í† ë¦¬ êµ¬ì¡°:
  ```
  onno-frontend/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ components/
  â”‚   â”‚   â”œâ”€â”€ AudioRecorder.tsx
  â”‚   â”‚   â”œâ”€â”€ TranscriptPanel.tsx
  â”‚   â”‚   â”œâ”€â”€ QuestionCard.tsx
  â”‚   â”‚   â””â”€â”€ MeetingRoom.tsx
  â”‚   â”œâ”€â”€ stores/
  â”‚   â”‚   â””â”€â”€ meetingStore.ts
  â”‚   â”œâ”€â”€ services/
  â”‚   â”‚   â””â”€â”€ websocket.ts
  â”‚   â”œâ”€â”€ App.tsx
  â”‚   â””â”€â”€ main.tsx
  â”œâ”€â”€ package.json
  â””â”€â”€ vite.config.ts
  ```

- [ ] **Backend í”„ë¡œì íŠ¸ ì´ˆê¸°í™”**
  ```bash
  mkdir onno-backend
  cd onno-backend
  npm init -y
  npm install express socket.io cors dotenv
  npm install -D typescript @types/express @types/node ts-node nodemon
  npx tsc --init
  ```

  ë””ë ‰í† ë¦¬ êµ¬ì¡°:
  ```
  onno-backend/
  â”œâ”€â”€ src/
  â”‚   â”œâ”€â”€ server.ts
  â”‚   â”œâ”€â”€ websocket/
  â”‚   â”‚   â””â”€â”€ meetingHandler.ts
  â”‚   â”œâ”€â”€ services/
  â”‚   â”‚   â”œâ”€â”€ sttService.ts
  â”‚   â”‚   â””â”€â”€ questionService.ts
  â”‚   â””â”€â”€ types/
  â”‚       â””â”€â”€ meeting.ts
  â”œâ”€â”€ package.json
  â””â”€â”€ tsconfig.json
  ```

- [ ] **AI Service í”„ë¡œì íŠ¸ ì´ˆê¸°í™”**
  ```bash
  mkdir onno-ai
  cd onno-ai
  python -m venv venv
  source venv/bin/activate  # Windows: venv\Scripts\activate
  pip install fastapi uvicorn openai python-multipart
  ```

  ë””ë ‰í† ë¦¬ êµ¬ì¡°:
  ```
  onno-ai/
  â”œâ”€â”€ app/
  â”‚   â”œâ”€â”€ main.py
  â”‚   â”œâ”€â”€ services/
  â”‚   â”‚   â”œâ”€â”€ stt.py
  â”‚   â”‚   â””â”€â”€ question_generator.py
  â”‚   â””â”€â”€ models/
  â”‚       â””â”€â”€ schemas.py
  â”œâ”€â”€ requirements.txt
  â””â”€â”€ .env
  ```

#### 1-2. API í‚¤ ë°œê¸‰

- [ ] **OpenAI API Key**
  - [ ] https://platform.openai.com/api-keys ì ‘ì†
  - [ ] API Key ìƒì„±
  - [ ] `.env` íŒŒì¼ì— ì €ì¥
    ```
    OPENAI_API_KEY=sk-...
    ```
  - [ ] Usage Limit ì„¤ì • ($50/month ì´ˆê¸°)

#### 1-3. Git ì €ì¥ì†Œ ì •ë¦¬

- [ ] **í”„ë¡œì íŠ¸ êµ¬ì¡° ì •ë¦¬**
  ```
  Onno/
  â”œâ”€â”€ frontend/     (Reactì•±)
  â”œâ”€â”€ backend/      (Node.js API + WebSocket)
  â”œâ”€â”€ ai-service/   (Python FastAPI)
  â”œâ”€â”€ docs/         (ê¸°ì¡´ ë¬¸ì„œë“¤)
  â”œâ”€â”€ README.md
  â””â”€â”€ TODO.md
  ```

- [ ] **.gitignore ì—…ë°ì´íŠ¸**
  ```
  # Dependencies
  node_modules/
  venv/
  __pycache__/

  # Env
  .env
  .env.local

  # Build
  dist/
  build/

  # IDE
  .vscode/
  .idea/
  ```

---

### ğŸ“… Step 2: í•µì‹¬ ê¸°ëŠ¥ í”„ë¡œí† íƒ€ì… (3-5ì¼)

**ëª©í‘œ**: ì‹¤ì‹œê°„ ìŒì„± â†’ ì „ì‚¬ â†’ AI ì§ˆë¬¸ ì œì•ˆ íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ì¸

#### 2-1. STT ì„œë¹„ìŠ¤ êµ¬í˜„

- [ ] **AI Service: STT ì—”ë“œí¬ì¸íŠ¸**
  ```python
  # onno-ai/app/services/stt.py

  from openai import OpenAI
  import time

  client = OpenAI()

  async def transcribe_audio(audio_file):
      start = time.time()

      response = client.audio.transcriptions.create(
          model="whisper-1",
          file=audio_file,
          language="ko",
          response_format="verbose_json"
      )

      latency = time.time() - start

      return {
          "text": response.text,
          "duration": response.duration,
          "latency": latency
      }
  ```

- [ ] **FastAPI ì—”ë“œí¬ì¸íŠ¸**
  ```python
  # onno-ai/app/main.py

  from fastapi import FastAPI, File, UploadFile
  from app.services.stt import transcribe_audio

  app = FastAPI()

  @app.post("/api/stt/transcribe")
  async def transcribe(audio: UploadFile = File(...)):
      result = await transcribe_audio(audio.file)
      return result
  ```

- [ ] **í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ íŒŒì¼ ì¤€ë¹„**
  - [ ] í•œêµ­ì–´ ë¹„ì¦ˆë‹ˆìŠ¤ íšŒì˜ ë…¹ìŒ 3ê°œ (ê° 1-3ë¶„)
  - [ ] MP3 ë˜ëŠ” WAV í˜•ì‹
  - [ ] `test-audio/` í´ë”ì— ì €ì¥

- [ ] **STT ì •í™•ë„ í…ŒìŠ¤íŠ¸**
  - [ ] 3ê°œ ìƒ˜í”Œ ì „ì‚¬
  - [ ] ìˆ˜ë™ìœ¼ë¡œ ì •í™•ë„ í™•ì¸
  - [ ] Latency ì¸¡ì • (ëª©í‘œ: <2ì´ˆ)

#### 2-2. AI ì§ˆë¬¸ ìƒì„± ì„œë¹„ìŠ¤ êµ¬í˜„

- [ ] **Prompt v0.1 ì‘ì„±**
  ```python
  # onno-ai/app/services/question_generator.py

  from openai import OpenAI

  client = OpenAI()

  QUESTION_PROMPT = """
  ë‹¹ì‹ ì€ VC íˆ¬ì ì‹¬ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

  ì•„ë˜ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬, íˆ¬ììê°€ ë†“ì¹˜ê¸° ì‰¬ìš´ ì¤‘ìš”í•œ ì§ˆë¬¸ 3ê°œë¥¼ ì œì•ˆí•˜ì„¸ìš”.

  ## ëŒ€í™” ì „ì‚¬:
  {transcript}

  ## ì¶œë ¥ í˜•ì‹ (JSON):
  {{
    "questions": [
      {{
        "text": "ì§ˆë¬¸ í…ìŠ¤íŠ¸",
        "priority": "critical" | "important" | "follow_up",
        "reason": "ì™œ ì´ ì§ˆë¬¸ì´ ì¤‘ìš”í•œì§€",
        "category": "metrics" | "team" | "strategy" | "risk"
      }}
    ]
  }}
  """

  async def generate_questions(transcript: str):
      response = client.chat.completions.create(
          model="gpt-4o",
          messages=[
              {"role": "system", "content": "You are an expert VC analyst."},
              {"role": "user", "content": QUESTION_PROMPT.format(transcript=transcript)}
          ],
          response_format={"type": "json_object"},
          temperature=0.7
      )

      return response.choices[0].message.content
  ```

- [ ] **FastAPI ì—”ë“œí¬ì¸íŠ¸**
  ```python
  @app.post("/api/questions/generate")
  async def generate_questions_endpoint(data: dict):
      transcript = data.get("transcript")
      questions = await generate_questions(transcript)
      return questions
  ```

- [ ] **í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 5ê°œ ì¤€ë¹„**
  ```
  ì‹œë‚˜ë¦¬ì˜¤ 1: CAC ì–¸ê¸‰, LTV ë¯¸ì–¸ê¸‰
  ì‹œë‚˜ë¦¬ì˜¤ 2: MRR ì–¸ê¸‰, Churn Rate ë¯¸ì–¸ê¸‰
  ì‹œë‚˜ë¦¬ì˜¤ 3: íŒ€ ì†Œê°œ, í•µì‹¬ ì¸ì¬ ë¯¸ì–¸ê¸‰
  ì‹œë‚˜ë¦¬ì˜¤ 4: ì‹œì¥ í¬ê¸° ì–¸ê¸‰, ê²½ìŸì‚¬ ë¯¸ì–¸ê¸‰
  ì‹œë‚˜ë¦¬ì˜¤ 5: ì œí’ˆ ì„¤ëª…, íƒ€ê²Ÿ ê³ ê° ë¯¸ì–¸ê¸‰
  ```

- [ ] **ì§ˆë¬¸ í’ˆì§ˆ í‰ê°€**
  - [ ] 5ê°œ ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰
  - [ ] ì ì ˆì„±, íƒ€ì´ë°, ì‹¤ìš©ì„± í‰ê°€ (5ì  ì²™ë„)
  - [ ] ì‘ë‹µ ì‹œê°„ ì¸¡ì • (ëª©í‘œ: <1ì´ˆ)

#### 2-3. WebSocket ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸

- [ ] **Backend: WebSocket ì„œë²„**
  ```typescript
  // onno-backend/src/server.ts

  import express from 'express';
  import { createServer } from 'http';
  import { Server } from 'socket.io';
  import cors from 'cors';

  const app = express();
  app.use(cors());

  const httpServer = createServer(app);
  const io = new Server(httpServer, {
    cors: { origin: "*" }
  });

  io.on('connection', (socket) => {
    console.log('Client connected:', socket.id);

    socket.on('join_meeting', (data) => {
      const { meetingId } = data;
      socket.join(`meeting-${meetingId}`);
      console.log(`Client joined meeting: ${meetingId}`);
    });

    socket.on('audio_chunk', async (data) => {
      // TODO: STT ì„œë¹„ìŠ¤ë¡œ ì˜¤ë””ì˜¤ ì „ì†¡
      // TODO: ì „ì‚¬ ê²°ê³¼ë¥¼ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡
    });

    socket.on('disconnect', () => {
      console.log('Client disconnected:', socket.id);
    });
  });

  httpServer.listen(3000, () => {
    console.log('Server running on http://localhost:3000');
  });
  ```

- [ ] **Frontend: WebSocket í´ë¼ì´ì–¸íŠ¸**
  ```typescript
  // onno-frontend/src/services/websocket.ts

  import { io, Socket } from 'socket.io-client';

  class WebSocketService {
    private socket: Socket | null = null;

    connect() {
      this.socket = io('http://localhost:3000');

      this.socket.on('connect', () => {
        console.log('Connected to server');
      });

      this.socket.on('transcription', (data) => {
        console.log('Transcription:', data);
        // TODO: Zustand store ì—…ë°ì´íŠ¸
      });

      this.socket.on('question_suggested', (data) => {
        console.log('Question:', data);
        // TODO: Zustand store ì—…ë°ì´íŠ¸
      });
    }

    joinMeeting(meetingId: string) {
      this.socket?.emit('join_meeting', { meetingId });
    }

    sendAudioChunk(meetingId: string, audioData: Blob) {
      this.socket?.emit('audio_chunk', { meetingId, audioData });
    }
  }

  export default new WebSocketService();
  ```

#### 2-4. ê°„ë‹¨í•œ UI êµ¬í˜„

- [ ] **AudioRecorder ì»´í¬ë„ŒíŠ¸**
  ```typescript
  // onno-frontend/src/components/AudioRecorder.tsx

  import { useState, useRef } from 'react';

  export function AudioRecorder({ onAudioChunk }: { onAudioChunk: (blob: Blob) => void }) {
    const [isRecording, setIsRecording] = useState(false);
    const mediaRecorderRef = useRef<MediaRecorder | null>(null);

    const startRecording = async () => {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mediaRecorder = new MediaRecorder(stream);

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          onAudioChunk(e.data);
        }
      };

      mediaRecorder.start(5000); // 5ì´ˆë§ˆë‹¤ chunk ì „ì†¡
      mediaRecorderRef.current = mediaRecorder;
      setIsRecording(true);
    };

    const stopRecording = () => {
      mediaRecorderRef.current?.stop();
      setIsRecording(false);
    };

    return (
      <div>
        <button onClick={isRecording ? stopRecording : startRecording}>
          {isRecording ? 'ì •ì§€' : 'ë…¹ìŒ ì‹œì‘'}
        </button>
      </div>
    );
  }
  ```

- [ ] **TranscriptPanel ì»´í¬ë„ŒíŠ¸**
  ```typescript
  // onno-frontend/src/components/TranscriptPanel.tsx

  export function TranscriptPanel({ transcripts }: { transcripts: Array<{text: string, timestamp: number}> }) {
    return (
      <div className="transcript-panel">
        <h3>ëŒ€í™” ë‚´ìš©</h3>
        {transcripts.map((t, i) => (
          <p key={i}>{t.text}</p>
        ))}
      </div>
    );
  }
  ```

- [ ] **QuestionCard ì»´í¬ë„ŒíŠ¸**
  ```typescript
  // onno-frontend/src/components/QuestionCard.tsx

  export function QuestionCard({ question }: { question: {text: string, priority: string, reason: string} }) {
    return (
      <div className={`question-card priority-${question.priority}`}>
        <span className="priority-badge">{question.priority}</span>
        <p className="question-text">{question.text}</p>
        <p className="reason">{question.reason}</p>
      </div>
    );
  }
  ```

- [ ] **MeetingRoom í†µí•© í™”ë©´**
  ```typescript
  // onno-frontend/src/components/MeetingRoom.tsx

  import { AudioRecorder } from './AudioRecorder';
  import { TranscriptPanel } from './TranscriptPanel';
  import { QuestionCard } from './QuestionCard';
  import { useMeetingStore } from '../stores/meetingStore';
  import websocketService from '../services/websocket';

  export function MeetingRoom() {
    const { transcripts, questions } = useMeetingStore();

    const handleAudioChunk = (blob: Blob) => {
      websocketService.sendAudioChunk('test-meeting-1', blob);
    };

    return (
      <div className="meeting-room">
        <h1>íšŒì˜ ì¤‘...</h1>

        <AudioRecorder onAudioChunk={handleAudioChunk} />

        <div className="content">
          <TranscriptPanel transcripts={transcripts} />

          <div className="questions">
            <h3>AI ì§ˆë¬¸ ì œì•ˆ</h3>
            {questions.map((q, i) => (
              <QuestionCard key={i} question={q} />
            ))}
          </div>
        </div>
      </div>
    );
  }
  ```

---

### ğŸ“… Step 3: ë°ì´í„° íë¦„ & ì‚¬ìš©ì ê²½í—˜ ê²€ì¦ (2-3ì¼)

#### 3-1. End-to-End í…ŒìŠ¤íŠ¸

- [ ] **ì „ì²´ íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ì¸**
  1. Frontendì—ì„œ ë…¹ìŒ ì‹œì‘
  2. Audio chunkê°€ Backend WebSocketìœ¼ë¡œ ì „ì†¡ë¨
  3. Backendê°€ AI Service STTë¡œ ì „ì†¡
  4. ì „ì‚¬ ê²°ê³¼ê°€ Frontendë¡œ ì‹¤ì‹œê°„ í‘œì‹œë¨
  5. ì „ì‚¬ê°€ ì¼ì • ê¸¸ì´ ë„ë‹¬ ì‹œ AI ì§ˆë¬¸ ìƒì„±
  6. ì§ˆë¬¸ì´ Frontendì— ì‹¤ì‹œê°„ í‘œì‹œë¨

- [ ] **Latency ì¸¡ì •**
  - [ ] ìŒì„± â†’ ì „ì‚¬: < 2ì´ˆ
  - [ ] ì „ì‚¬ â†’ ì§ˆë¬¸: < 1ì´ˆ
  - [ ] Total: < 3ì´ˆ

- [ ] **ì‚¬ìš©ì ì¸í„°ë™ì…˜ í…ŒìŠ¤íŠ¸**
  - [ ] ì§ˆë¬¸ ì¹´ë“œ í´ë¦­ â†’ "ì‚¬ìš©" í‘œì‹œ
  - [ ] ì§ˆë¬¸ ë¬´ì‹œ â†’ Fade out
  - [ ] ìƒˆ ì§ˆë¬¸ì´ ê³„ì† ìƒì„±ë¨

#### 3-2. í”„ë¡œí† íƒ€ì… ê°œì„ 

- [ ] **ë°œê²¬ëœ ë¬¸ì œì  ê¸°ë¡**
  - Latency ë³‘ëª© ì§€ì 
  - ì‚¬ìš©ì ê²½í—˜ ê°œì„ ì 
  - ê¸°ìˆ ì  ì œì•½ì‚¬í•­

- [ ] **ê°œì„  ìš°ì„ ìˆœìœ„ ê²°ì •**
  - P0: ì¹˜ëª…ì  ë¬¸ì œ (ì¦‰ì‹œ í•´ê²°)
  - P1: ì¤‘ìš” ë¬¸ì œ (ë‹¤ìŒ iteration)
  - P2: ê°œì„ ì‚¬í•­ (í–¥í›„ ê³ ë ¤)

---

### ğŸ“… Step 4: ë‹¤ìŒ ë‹¨ê³„ ê²°ì • (1ì¼)

#### 4-1. í”„ë¡œí† íƒ€ì… í‰ê°€

- [ ] **ê¸°ìˆ  ê²€ì¦ ì™„ë£Œ ì—¬ë¶€**
  - STT ì •í™•ë„ 95%+
  - Latency < 3ì´ˆ
  - AI ì§ˆë¬¸ í’ˆì§ˆ í‰ê°€

- [ ] **ì‚¬ìš©ì ê²½í—˜ í‰ê°€**
  - ë°ì´í„° íë¦„ì´ ì§ê´€ì ì¸ê°€?
  - ì¸í„°ë™ì…˜ì´ ìì—°ìŠ¤ëŸ¬ìš´ê°€?
  - "ì‹¤ì‹œê°„" ëŠë‚Œì´ ì „ë‹¬ë˜ëŠ”ê°€?

#### 4-2. ë‹¤ìŒ ë‹¨ê³„ ê³„íš

**Option A: í”„ë¡œí† íƒ€ì… ì™„ì„±ë„ ë†’ì´ê¸°**
- ê°œì¸í™” ì‹œìŠ¤í…œ ì¶”ê°€ (Lv.1 ê¸°ë³¸)
- íšŒì˜ íˆìŠ¤í† ë¦¬ ì €ì¥
- UI/UX ê°œì„ 

**Option B: í™•ì¥ ê¸°ëŠ¥ ì¶”ê°€**
- ê´€ê³„ ê°ì²´ ì‹œìŠ¤í…œ í”„ë¡œí† íƒ€ì…
- Notion ì—°ë™
- í˜ë¥´ì†Œë‚˜ ì„ íƒ

**Option C: MVPë¡œ ë°œì „**
- DB ì—°ë™ (PostgreSQL)
- ì¸ì¦ ì‹œìŠ¤í…œ
- ë°°í¬ ì¤€ë¹„

---

## ğŸ“Š í”„ë¡œí† íƒ€ì… ì„±ê³µ ì§€í‘œ

### í•„ìˆ˜ (Must-have)
- [ ] STT ì •í™•ë„ 90%+
- [ ] End-to-End Latency < 5ì´ˆ
- [ ] AI ì§ˆë¬¸ 3ê°œ ì´ìƒ ìƒì„± (3ë¶„ íšŒì˜ ê¸°ì¤€)
- [ ] ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ ë™ì‘

### ëª©í‘œ (Should-have)
- [ ] STT ì •í™•ë„ 95%+
- [ ] Latency < 3ì´ˆ
- [ ] ì§ˆë¬¸ í’ˆì§ˆ í‰ê°€ 4.0+ (5ì  ì²™ë„)
- [ ] ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ (ë³¸ì¸ + 1-2ëª…)

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ê³„ì„œ](docs/Onno%20-%20ì‹œìŠ¤í…œ%20ì•„í‚¤í…ì²˜%20ì„¤ê³„ì„œ%20(System%20Architecture%20Design).md)
- [PRD Part 2: ê¸°ëŠ¥ ëª…ì„¸](docs/Onno%20-%20PRD%20Part%202%20ì—…ë°ì´íŠ¸%20(ê°œì¸í™”%20í†µí•©).md)
- [PRD Part 3: ê¸°ìˆ  ì•„í‚¤í…ì²˜](docs/Onno%20-%20PRD%20Part%203%20(ê¸°ìˆ %20ì•„í‚¤í…ì²˜).md)

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-12-02 by Claude
**ë‹¤ìŒ ì—…ë°ì´íŠ¸ ì˜ˆì •**: Step 1 ì™„ë£Œ í›„ (ê°œë°œ í™˜ê²½ êµ¬ì¶• ê²°ê³¼ ë°˜ì˜)

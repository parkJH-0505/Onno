# Iteration 1: í”„ë¡œí† íƒ€ì… ê°œë°œ ê³„íš

**ì‘ì„±ì¼**: 2025-12-02
**ë‹´ë‹¹**: ë°•ì¤€í™ + Claude
**ê¸°ê°„**: 7-10ì¼ (2025-12-02 ~ 2025-12-12)
**ëª©í‘œ**: í•µì‹¬ ê¸°ëŠ¥ í”„ë¡œí† íƒ€ì… ì™„ì„± ë° ì•„í‚¤í…ì²˜ ê²€ì¦

---

## ğŸ“‹ Iteration 1 ê°œìš”

### ğŸ¯ ëª©í‘œ (Goal)

1. **ì•„í‚¤í…ì²˜ ê²€ì¦**: Phase 0ì—ì„œ ì„¤ê³„í•œ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ê°€ ì‹¤ì œë¡œ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸
2. **í•µì‹¬ ë°ì´í„° íë¦„ êµ¬í˜„**: ìŒì„± â†’ ì „ì‚¬ â†’ AI ì§ˆë¬¸ íŒŒì´í”„ë¼ì¸ ë™ì‘
3. **ì‚¬ìš©ì ê²½í—˜ í™•ì¸**: ì‹¤ì‹œê°„ ì¸í„°ë™ì…˜ì´ ì§ê´€ì ì´ê³  ìì—°ìŠ¤ëŸ¬ìš´ì§€ ê²€ì¦
4. **ê¸°ìˆ ì  ì‹¤í˜„ ê°€ëŠ¥ì„± ì¦ëª…**: STT ì •í™•ë„, Latency, AI ì§ˆë¬¸ í’ˆì§ˆ ì¸¡ì •

### ğŸš« ë²”ìœ„ ë°– (Out of Scope)

ì´ë²ˆ Iterationì—ì„œëŠ” **í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤**:
- âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ë™ (PostgreSQL, Redis)
- âŒ ì‚¬ìš©ì ì¸ì¦/íšŒì›ê°€ì…
- âŒ ê°œì¸í™” ì‹œìŠ¤í…œ (Lv.1-5, í˜ë¥´ì†Œë‚˜)
- âŒ ê´€ê³„ ê°ì²´ ì‹œìŠ¤í…œ
- âŒ Notion ì—°ë™
- âŒ AWS ë°°í¬
- âŒ í”„ë¡œë•ì…˜ ë ˆë²¨ ì—ëŸ¬ í•¸ë“¤ë§

### âœ… ì„±ê³µ ê¸°ì¤€ (Success Criteria)

**í•„ìˆ˜ (Must-have)**:
- [ ] STT ì •í™•ë„ 90%+ (í•œêµ­ì–´ ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€í™” ê¸°ì¤€)
- [ ] End-to-End Latency < 5ì´ˆ (ìŒì„± ì…ë ¥ â†’ í™”ë©´ í‘œì‹œ)
- [ ] AI ì§ˆë¬¸ 3ê°œ ì´ìƒ ìƒì„± (3ë¶„ íšŒì˜ ê¸°ì¤€)
- [ ] ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ ë™ì‘ (WebSocket)

**ëª©í‘œ (Should-have)**:
- [ ] STT ì •í™•ë„ 95%+
- [ ] Latency < 3ì´ˆ
- [ ] AI ì§ˆë¬¸ í’ˆì§ˆ í‰ê°€ 4.0+/5.0 (ì ì ˆì„±, íƒ€ì´ë°, ì‹¤ìš©ì„±)
- [ ] ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ (ë³¸ì¸ + 1-2ëª… í…ŒìŠ¤íŠ¸)

---

## ğŸ“… 4ë‹¨ê³„ ì‹¤í–‰ ê³„íš

### Phase 1-1: í”„ë¡œì íŠ¸ ì´ˆê¸°í™” (Day 1-2) âœ… COMPLETED

**ì˜ˆìƒ ì†Œìš”**: 1-2ì¼
**ì‹¤ì œ ì†Œìš”**: 1ì¼
**ìš°ì„ ìˆœìœ„**: ğŸ”¥ Critical
**ì™„ë£Œì¼**: 2025-12-02

#### ì™„ë£Œ ìš”ì•½
- âœ… Frontend, Backend, AI Service 3ê°œ í”„ë¡œì íŠ¸ ìƒì„± ì™„ë£Œ
- âœ… ëª¨ë“  ì˜ì¡´ì„± ì„¤ì¹˜ ë° í™˜ê²½ ì„¤ì • ì™„ë£Œ
- âœ… TypeScript ESM ëª¨ë“œ ì„¤ì • (tsx ì‚¬ìš©)
- âœ… 6000ë²ˆëŒ€ í¬íŠ¸ë¡œ í†µì¼ (AI: 6000, Backend: 6001, Frontend: 6005)
- âœ… OpenAI API Key ì„¤ì • ì™„ë£Œ
- âœ… WebSocket í†µì‹  êµ¬ì¡° êµ¬í˜„ ì™„ë£Œ
- âœ… ê¸°ë³¸ UI ì»´í¬ë„ŒíŠ¸ êµ¬ì¡° ìƒì„± ì™„ë£Œ
- âš ï¸ Frontend ëª¨ë“ˆ import ì´ìŠˆ í•´ê²° (import type ì‚¬ìš©)

#### ì‹¤ì œ êµ¬í˜„ëœ ì•„í‚¤í…ì²˜
```
Onno/
â”œâ”€â”€ frontend/ (React 18 + TypeScript + Vite + Zustand)
â”‚   â”œâ”€â”€ Port: 6005
â”‚   â”œâ”€â”€ Stack: socket.io-client, zustand
â”‚   â””â”€â”€ Components: AudioRecorder, TranscriptPanel, QuestionCard, MeetingRoom
â”œâ”€â”€ backend/ (Node.js + Express + Socket.io + tsx)
â”‚   â”œâ”€â”€ Port: 6001
â”‚   â”œâ”€â”€ Stack: express, socket.io, axios, form-data
â”‚   â””â”€â”€ Type: ESM module ("type": "module" in package.json)
â””â”€â”€ ai-service/ (Python 3.13 + FastAPI + OpenAI SDK)
    â”œâ”€â”€ Port: 6000
    â”œâ”€â”€ Stack: fastapi, openai, python-dotenv
    â””â”€â”€ Services: STT (Whisper), Question Generator (GPT-4o)
```

#### Task 1.1.1: í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„± âœ…

**ì‘ì—… ë‚´ìš©**:
1. **Frontend í”„ë¡œì íŠ¸** (React + TypeScript + Vite)
   ```bash
   npm create vite@latest onno-frontend -- --template react-ts
   cd onno-frontend
   npm install
   npm install zustand socket.io-client
   npm install -D @types/node
   ```

2. **Backend í”„ë¡œì íŠ¸** (Node.js + Express + Socket.io)
   ```bash
   mkdir onno-backend
   cd onno-backend
   npm init -y
   npm install express socket.io cors dotenv
   npm install -D typescript @types/express @types/socket.io @types/node ts-node nodemon
   npx tsc --init
   ```

3. **AI Service** (Python + FastAPI)
   ```bash
   mkdir onno-ai
   cd onno-ai
   python -m venv venv
   source venv/bin/activate  # Windows: venv\Scripts\activate
   pip install fastapi uvicorn openai python-multipart python-dotenv
   ```

**ë””ë ‰í† ë¦¬ êµ¬ì¡°**:
```
Onno/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioRecorder.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ TranscriptPanel.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ QuestionCard.tsx
â”‚   â”‚   â”‚   â””â”€â”€ MeetingRoom.tsx
â”‚   â”‚   â”œâ”€â”€ stores/
â”‚   â”‚   â”‚   â””â”€â”€ meetingStore.ts
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â””â”€â”€ websocket.ts
â”‚   â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â”‚   â””â”€â”€ meeting.ts
â”‚   â”‚   â”œâ”€â”€ App.tsx
â”‚   â”‚   â””â”€â”€ main.tsx
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ server.ts
â”‚   â”‚   â”œâ”€â”€ websocket/
â”‚   â”‚   â”‚   â””â”€â”€ meetingHandler.ts
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ sttService.ts
â”‚   â”‚   â”‚   â””â”€â”€ questionService.ts
â”‚   â”‚   â””â”€â”€ types/
â”‚   â”‚       â””â”€â”€ meeting.ts
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ ai-service/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ stt.py
â”‚   â”‚   â”‚   â””â”€â”€ question_generator.py
â”‚   â”‚   â””â”€â”€ models/
â”‚   â”‚       â””â”€â”€ schemas.py
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env
â”‚
â”œâ”€â”€ docs/
â”œâ”€â”€ test-data/
â”‚   â””â”€â”€ audio-samples/
â”œâ”€â”€ README.md
â””â”€â”€ TODO.md
```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] 3ê°œ í”„ë¡œì íŠ¸ í´ë” ìƒì„±
- [ ] ëª¨ë“  íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ
- [ ] `npm run dev` / `uvicorn main:app` ì‹¤í–‰ ê°€ëŠ¥
- [ ] Gitì— ì´ˆê¸° êµ¬ì¡° ì»¤ë°‹

**ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„

---

#### Task 1.1.2: í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì • íŒŒì¼

**ì‘ì—… ë‚´ìš©**:

1. **AI Service `.env`**
   ```
   OPENAI_API_KEY=sk-...
   ENVIRONMENT=development
   ```

2. **Backend `.env`**
   ```
   PORT=3000
   AI_SERVICE_URL=http://localhost:8000
   ENVIRONMENT=development
   ```

3. **Frontend `.env`**
   ```
   VITE_WS_URL=http://localhost:3000
   ```

4. **`.gitignore` ì—…ë°ì´íŠ¸**
   ```
   # Dependencies
   node_modules/
   venv/
   __pycache__/

   # Env
   .env
   .env.local

   # Build
   dist/
   build/

   # IDE
   .vscode/
   .idea/

   # Test data
   test-data/audio-samples/*.mp3
   test-data/audio-samples/*.wav
   ```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] OpenAI API Key ë°œê¸‰ ë° ì €ì¥
- [ ] ëª¨ë“  `.env` íŒŒì¼ ìƒì„±
- [ ] `.gitignore` ì—…ë°ì´íŠ¸
- [ ] API Usage Limit ì„¤ì • ($50/month)

**ì˜ˆìƒ ì‹œê°„**: 30ë¶„

---

#### Task 1.1.3: ê¸°ë³¸ ì„œë²„ êµ¬ë™ í™•ì¸

**ì‘ì—… ë‚´ìš©**:

1. **AI Service ê¸°ë³¸ ì„œë²„**
   ```python
   # ai-service/app/main.py
   from fastapi import FastAPI

   app = FastAPI()

   @app.get("/health")
   async def health():
       return {"status": "ok"}
   ```

   ì‹¤í–‰: `uvicorn app.main:app --reload --port 8000`

2. **Backend ê¸°ë³¸ ì„œë²„**
   ```typescript
   // backend/src/server.ts
   import express from 'express';

   const app = express();
   const PORT = 3000;

   app.get('/health', (req, res) => {
     res.json({ status: 'ok' });
   });

   app.listen(PORT, () => {
     console.log(`Server running on port ${PORT}`);
   });
   ```

   ì‹¤í–‰: `npx ts-node src/server.ts`

3. **Frontend ê¸°ë³¸ í™”ë©´**
   ```tsx
   // frontend/src/App.tsx
   function App() {
     return <h1>Onno Prototype</h1>
   }
   ```

   ì‹¤í–‰: `npm run dev`

**ì™„ë£Œ ì¡°ê±´**:
- [x] AI Service: http://localhost:6000/health ì‘ë‹µ
- [x] Backend: http://localhost:6001/health ì‘ë‹µ (Socket.io í¬í•¨)
- [x] Frontend: http://localhost:6005 í™”ë©´ í‘œì‹œ
- [x] 3ê°œ ì„œë²„ ë™ì‹œ ì‹¤í–‰ ê°€ëŠ¥

**ì˜ˆìƒ ì‹œê°„**: 1ì‹œê°„
**ì‹¤ì œ ì‹œê°„**: 4ì‹œê°„ (í™˜ê²½ ì„¤ì • íŠ¸ëŸ¬ë¸”ìŠˆíŒ… í¬í•¨)

---

### Phase 1-2: STT ì„œë¹„ìŠ¤ êµ¬í˜„ (Day 3-4)

**ì˜ˆìƒ ì†Œìš”**: 2ì¼
**ìš°ì„ ìˆœìœ„**: ğŸ”¥ Critical

#### Task 1.2.1: OpenAI Whisper API í…ŒìŠ¤íŠ¸

**ì‘ì—… ë‚´ìš©**:

1. **í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒ˜í”Œ ì¤€ë¹„**
   - í•œêµ­ì–´ ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€í™” ë…¹ìŒ 3ê°œ ì¤€ë¹„
   - ê° 1-3ë¶„ ê¸¸ì´
   - MP3 ë˜ëŠ” WAV í˜•ì‹
   - `test-data/audio-samples/` í´ë”ì— ì €ì¥

   ì˜ˆì‹œ:
   - `sample-1-vc-pitch.mp3`: VC íˆ¬ì ì‹¬ì‚¬ ì‹œë®¬ë ˆì´ì…˜
   - `sample-2-mentor-call.mp3`: AC ë©˜í† ë§ ëŒ€í™”
   - `sample-3-sales-call.mp3`: CB ì„¸ì¼ì¦ˆ ì½œ

2. **ê°„ë‹¨í•œ STT í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸**
   ```python
   # ai-service/test_stt.py
   from openai import OpenAI
   import time
   import os

   client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

   def test_transcription(audio_file_path):
       print(f"\n{'='*50}")
       print(f"Testing: {audio_file_path}")
       print(f"{'='*50}")

       start_time = time.time()

       with open(audio_file_path, 'rb') as audio_file:
           response = client.audio.transcriptions.create(
               model="whisper-1",
               file=audio_file,
               language="ko",
               response_format="verbose_json"
           )

       latency = time.time() - start_time

       print(f"\nğŸ“ ì „ì‚¬ ê²°ê³¼:")
       print(response.text)
       print(f"\nâ±ï¸ Latency: {latency:.2f}ì´ˆ")
       print(f"ğŸ“Š ì˜¤ë””ì˜¤ ê¸¸ì´: {response.duration:.2f}ì´ˆ")
       print(f"ğŸ“ˆ ì²˜ë¦¬ ë¹„ìœ¨: {response.duration / latency:.2f}x")

       return {
           "text": response.text,
           "duration": response.duration,
           "latency": latency,
           "file": audio_file_path
       }

   if __name__ == "__main__":
       samples = [
           "../test-data/audio-samples/sample-1-vc-pitch.mp3",
           "../test-data/audio-samples/sample-2-mentor-call.mp3",
           "../test-data/audio-samples/sample-3-sales-call.mp3"
       ]

       results = []
       for sample in samples:
           if os.path.exists(sample):
               result = test_transcription(sample)
               results.append(result)

       # í‰ê·  ì§€í‘œ ì¶œë ¥
       avg_latency = sum(r['latency'] for r in results) / len(results)
       print(f"\n{'='*50}")
       print(f"í‰ê·  Latency: {avg_latency:.2f}ì´ˆ")
       print(f"ëª©í‘œ ë‹¬ì„±: {'âœ…' if avg_latency < 2.0 else 'âŒ'} (ëª©í‘œ: <2ì´ˆ)")
   ```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] 3ê°œ ì˜¤ë””ì˜¤ ìƒ˜í”Œ ì¤€ë¹„ ì™„ë£Œ
- [ ] STT í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì„±ê³µ
- [ ] ì „ì‚¬ ì •í™•ë„ ìˆ˜ë™ í™•ì¸ (90%+ ëª©í‘œ)
- [ ] Latency ì¸¡ì • ê²°ê³¼ ê¸°ë¡
- [ ] í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ `docs/test-results/iteration-1-stt.md`ì— ë¬¸ì„œí™”

**ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„

---

#### Task 1.2.2: STT Service API êµ¬í˜„

**ì‘ì—… ë‚´ìš©**:

1. **STT Service ëª¨ë“ˆ**
   ```python
   # ai-service/app/services/stt.py
   from openai import OpenAI
   import time
   import os

   client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

   async def transcribe_audio(audio_file):
       """
       ìŒì„± íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ì „ì‚¬

       Args:
           audio_file: ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼

       Returns:
           dict: {
               "text": str,
               "duration": float,
               "latency": float
           }
       """
       start_time = time.time()

       response = client.audio.transcriptions.create(
           model="whisper-1",
           file=audio_file,
           language="ko",
           response_format="verbose_json"
       )

       latency = time.time() - start_time

       return {
           "text": response.text,
           "duration": response.duration,
           "latency": latency
       }
   ```

2. **FastAPI ì—”ë“œí¬ì¸íŠ¸**
   ```python
   # ai-service/app/main.py
   from fastapi import FastAPI, File, UploadFile, HTTPException
   from fastapi.middleware.cors import CORSMiddleware
   from app.services.stt import transcribe_audio
   import logging

   app = FastAPI(title="Onno AI Service")

   # CORS ì„¤ì •
   app.add_middleware(
       CORSMiddleware,
       allow_origins=["*"],
       allow_credentials=True,
       allow_methods=["*"],
       allow_headers=["*"],
   )

   # ë¡œê¹… ì„¤ì •
   logging.basicConfig(level=logging.INFO)
   logger = logging.getLogger(__name__)

   @app.get("/health")
   async def health():
       return {"status": "ok", "service": "onno-ai"}

   @app.post("/api/stt/transcribe")
   async def transcribe(audio: UploadFile = File(...)):
       """
       ìŒì„± íŒŒì¼ì„ ë°›ì•„ í…ìŠ¤íŠ¸ë¡œ ì „ì‚¬
       """
       try:
           logger.info(f"Transcribing audio: {audio.filename}")

           result = await transcribe_audio(audio.file)

           logger.info(f"Transcription complete: {result['latency']:.2f}s")

           return result

       except Exception as e:
           logger.error(f"Transcription error: {str(e)}")
           raise HTTPException(status_code=500, detail=str(e))
   ```

3. **Postman/cURL í…ŒìŠ¤íŠ¸**
   ```bash
   # cURLë¡œ API í…ŒìŠ¤íŠ¸
   curl -X POST "http://localhost:8000/api/stt/transcribe" \
     -F "audio=@test-data/audio-samples/sample-1-vc-pitch.mp3"
   ```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] STT Service ëª¨ë“ˆ êµ¬í˜„
- [ ] FastAPI ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
- [ ] CORS ì„¤ì • ì™„ë£Œ
- [ ] ë¡œê¹… ì„¤ì • ì™„ë£Œ
- [ ] Postman/cURLë¡œ API í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] ì—ëŸ¬ í•¸ë“¤ë§ êµ¬í˜„

**ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„

---

### Phase 1-3: AI ì§ˆë¬¸ ìƒì„± ì„œë¹„ìŠ¤ (Day 4-5)

**ì˜ˆìƒ ì†Œìš”**: 1-2ì¼
**ìš°ì„ ìˆœìœ„**: ğŸ”¥ Critical

#### Task 1.3.1: Prompt Engineering v0.1

**ì‘ì—… ë‚´ìš©**:

1. **ì§ˆë¬¸ ìƒì„± Prompt ì„¤ê³„**
   ```python
   # ai-service/app/services/question_generator.py
   from openai import OpenAI
   import os
   import json

   client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

   QUESTION_GENERATION_PROMPT = """
   ë‹¹ì‹ ì€ ê²½í—˜ì´ í’ë¶€í•œ VC(Venture Capital) íˆ¬ì ì‹¬ì‚¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

   ì•„ë˜ ëŒ€í™”ë¥¼ ë¶„ì„í•˜ì—¬, íˆ¬ììê°€ ë†“ì¹˜ê¸° ì‰¬ìš´ **ì¤‘ìš”í•œ ì§ˆë¬¸ 3ê°œ**ë¥¼ ì œì•ˆí•˜ì„¸ìš”.

   ## ëŒ€í™” ì „ì‚¬:
   {transcript}

   ## ì§ˆë¬¸ ìƒì„± ê°€ì´ë“œë¼ì¸:
   1. **ì´ë¯¸ ì–¸ê¸‰ëœ ë‚´ìš©ì€ ì§ˆë¬¸í•˜ì§€ ë§ˆì„¸ìš”**
   2. **íˆ¬ì ì˜ì‚¬ê²°ì •ì— í•„ìˆ˜ì ì¸ ì •ë³´**ë¥¼ ë¬»ëŠ” ì§ˆë¬¸ì„ ìš°ì„ í•©ë‹ˆë‹¤
   3. **êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì§ˆë¬¸**ì„ ë§Œë“œì„¸ìš”
   4. **ì¹´í…Œê³ ë¦¬ë³„ ê· í˜•**ì„ ë§ì¶”ì„¸ìš” (metrics, team, strategy, risk)

   ## ì¶œë ¥ í˜•ì‹ (JSON):
   {{
     "questions": [
       {{
         "text": "êµ¬ì²´ì ì¸ ì§ˆë¬¸ í…ìŠ¤íŠ¸ (í•œêµ­ì–´)",
         "priority": "critical" | "important" | "follow_up",
         "reason": "ì´ ì§ˆë¬¸ì´ ì™œ ì¤‘ìš”í•œì§€ ê°„ë‹¨íˆ ì„¤ëª… (1-2ë¬¸ì¥)",
         "category": "metrics" | "team" | "strategy" | "risk"
       }}
     ]
   }}

   ## Priority ì •ì˜:
   - **critical**: íˆ¬ì ì˜ì‚¬ê²°ì •ì— í•„ìˆ˜ì ì¸ ì •ë³´
   - **important**: ì¤‘ìš”í•˜ì§€ë§Œ ë‚˜ì¤‘ì— ë¬¼ì–´ë„ ë˜ëŠ” ì§ˆë¬¸
   - **follow_up**: ì¶”ê°€ì ì¸ ë””í…Œì¼ì„ í™•ì¸í•˜ëŠ” ì§ˆë¬¸
   """

   async def generate_questions(transcript: str):
       """
       ëŒ€í™” ì „ì‚¬ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ AI ì§ˆë¬¸ ìƒì„±

       Args:
           transcript: ëŒ€í™” ì „ì‚¬ í…ìŠ¤íŠ¸

       Returns:
           dict: {
               "questions": [
                   {
                       "text": str,
                       "priority": str,
                       "reason": str,
                       "category": str
                   }
               ]
           }
       """
       response = client.chat.completions.create(
           model="gpt-4o",
           messages=[
               {
                   "role": "system",
                   "content": "You are an expert VC investment analyst."
               },
               {
                   "role": "user",
                   "content": QUESTION_GENERATION_PROMPT.format(transcript=transcript)
               }
           ],
           response_format={"type": "json_object"},
           temperature=0.7
       )

       result = json.loads(response.choices[0].message.content)
       return result
   ```

2. **í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ 5ê°œ ì¤€ë¹„**
   ```python
   # ai-service/test_questions.py
   import asyncio
   from app.services.question_generator import generate_questions

   test_scenarios = [
       {
           "name": "ì‹œë‚˜ë¦¬ì˜¤ 1: CAC ì–¸ê¸‰, LTV ë¯¸ì–¸ê¸‰",
           "transcript": """
           íˆ¬ìì: ê³ ê° íšë“ ë¹„ìš©ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?
           ì°½ì—…ì: ì €í¬ CACëŠ” ì•½ 3ë§Œì›ì…ë‹ˆë‹¤. ì£¼ë¡œ í˜ì´ìŠ¤ë¶ ê´‘ê³ ë¥¼ í†µí•´ ê³ ê°ì„ ìœ ì¹˜í•˜ê³  ìˆê³ ìš”.
           íˆ¬ìì: ê·¸ë ‡êµ°ìš”. í˜„ì¬ ì›”ê°„ í™œì„± ì‚¬ìš©ìëŠ”?
           ì°½ì—…ì: í˜„ì¬ MAUëŠ” ì•½ 5000ëª…ì…ë‹ˆë‹¤.
           """,
           "expected": "LTVëŠ” ì–¼ë§ˆì¸ê°€ìš”?"
       },
       {
           "name": "ì‹œë‚˜ë¦¬ì˜¤ 2: MRR ì–¸ê¸‰, Churn Rate ë¯¸ì–¸ê¸‰",
           "transcript": """
           ì°½ì—…ì: ì €í¬ í˜„ì¬ MRRì€ 5000ë§Œì›ì…ë‹ˆë‹¤. ì§€ë‚œ 3ê°œì›”ê°„ 30% ì„±ì¥í–ˆìŠµë‹ˆë‹¤.
           íˆ¬ìì: ìœ ë£Œ ê³ ê°ì€ ëª‡ ëª…ì¸ê°€ìš”?
           ì°½ì—…ì: í˜„ì¬ 250ëª…ì…ë‹ˆë‹¤. ê°œì¸ í”Œëœì´ ëŒ€ë¶€ë¶„ì´ê³ ìš”.
           íˆ¬ìì: í‰ê·  ê²°ì œ ê¸ˆì•¡ì€?
           ì°½ì—…ì: ARPUëŠ” 20ë§Œì›ì…ë‹ˆë‹¤.
           """,
           "expected": "Churn RateëŠ” ì–¼ë§ˆì¸ê°€ìš”?"
       },
       # ... ë‚˜ë¨¸ì§€ 3ê°œ ì‹œë‚˜ë¦¬ì˜¤
   ]

   async def test_question_generation():
       for scenario in test_scenarios:
           print(f"\n{'='*60}")
           print(f"ğŸ§ª {scenario['name']}")
           print(f"{'='*60}")
           print(f"\nì…ë ¥ ëŒ€í™”:\n{scenario['transcript']}")

           result = await generate_questions(scenario['transcript'])

           print(f"\nìƒì„±ëœ ì§ˆë¬¸:")
           for i, q in enumerate(result['questions'], 1):
               print(f"\n{i}. [{q['priority']}] {q['text']}")
               print(f"   ì´ìœ : {q['reason']}")
               print(f"   ì¹´í…Œê³ ë¦¬: {q['category']}")

           print(f"\nê¸°ëŒ€ ì§ˆë¬¸: {scenario['expected']}")
           print(f"í¬í•¨ ì—¬ë¶€: {'âœ…' if any(scenario['expected'] in q['text'] for q in result['questions']) else 'âŒ'}")

   if __name__ == "__main__":
       asyncio.run(test_question_generation())
   ```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] Prompt v0.1 ì‘ì„±
- [ ] 5ê°œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì¤€ë¹„
- [ ] í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë° ê²°ê³¼ í‰ê°€
- [ ] ì§ˆë¬¸ í’ˆì§ˆ í‰ê°€ (ì ì ˆì„±, íƒ€ì´ë°, ì‹¤ìš©ì„± - 5ì  ì²™ë„)
- [ ] Prompt ê°œì„  (í•„ìš” ì‹œ)
- [ ] í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¬¸ì„œí™” (`docs/test-results/iteration-1-questions.md`)

**ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„

---

#### Task 1.3.2: ì§ˆë¬¸ ìƒì„± API êµ¬í˜„

**ì‘ì—… ë‚´ìš©**:

1. **FastAPI ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€**
   ```python
   # ai-service/app/main.pyì— ì¶”ê°€
   from app.services.question_generator import generate_questions
   from pydantic import BaseModel

   class QuestionRequest(BaseModel):
       transcript: str

   @app.post("/api/questions/generate")
   async def generate_questions_endpoint(request: QuestionRequest):
       """
       ëŒ€í™” ì „ì‚¬ë¥¼ ë°›ì•„ AI ì§ˆë¬¸ ìƒì„±
       """
       try:
           logger.info(f"Generating questions for transcript length: {len(request.transcript)}")

           result = await generate_questions(request.transcript)

           logger.info(f"Generated {len(result['questions'])} questions")

           return result

       except Exception as e:
           logger.error(f"Question generation error: {str(e)}")
           raise HTTPException(status_code=500, detail=str(e))
   ```

2. **Postman í…ŒìŠ¤íŠ¸**
   ```bash
   curl -X POST "http://localhost:8000/api/questions/generate" \
     -H "Content-Type: application/json" \
     -d '{
       "transcript": "íˆ¬ìì: CACê°€ ì–´ë–»ê²Œ ë˜ë‚˜ìš”? ì°½ì—…ì: 3ë§Œì›ì…ë‹ˆë‹¤."
     }'
   ```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„
- [ ] Request/Response ìŠ¤í‚¤ë§ˆ ì •ì˜
- [ ] Postman í…ŒìŠ¤íŠ¸ ì„±ê³µ
- [ ] ì‘ë‹µ ì‹œê°„ ì¸¡ì • (ëª©í‘œ: <1ì´ˆ)

**ì˜ˆìƒ ì‹œê°„**: 1-2ì‹œê°„

---

### Phase 1-4: WebSocket ì‹¤ì‹œê°„ íŒŒì´í”„ë¼ì¸ (Day 6-7)

**ì˜ˆìƒ ì†Œìš”**: 2ì¼
**ìš°ì„ ìˆœìœ„**: ğŸ”¥ Critical

#### Task 1.4.1: Backend WebSocket ì„œë²„

**ì‘ì—… ë‚´ìš©**:

1. **WebSocket ì„œë²„ êµ¬í˜„**
   ```typescript
   // backend/src/server.ts
   import express from 'express';
   import { createServer } from 'http';
   import { Server } from 'socket.io';
   import cors from 'cors';
   import axios from 'axios';
   import FormData from 'form-data';

   const app = express();
   app.use(cors());
   app.use(express.json());

   const httpServer = createServer(app);
   const io = new Server(httpServer, {
     cors: { origin: "*" }
   });

   const AI_SERVICE_URL = process.env.AI_SERVICE_URL || 'http://localhost:8000';

   // Health check
   app.get('/health', (req, res) => {
     res.json({ status: 'ok', service: 'onno-backend' });
   });

   // WebSocket ì—°ê²° ì²˜ë¦¬
   io.on('connection', (socket) => {
     console.log('Client connected:', socket.id);

     socket.on('join_meeting', (data) => {
       const { meetingId, userId } = data;
       socket.join(`meeting-${meetingId}`);
       console.log(`User ${userId} joined meeting ${meetingId}`);

       // ì°¸ê°€ìì—ê²Œ ì•Œë¦¼
       socket.to(`meeting-${meetingId}`).emit('participant_joined', {
         userId,
         timestamp: new Date().toISOString()
       });
     });

     socket.on('audio_chunk', async (data) => {
       const { meetingId, audioData } = data;

       try {
         // AI Serviceë¡œ ì˜¤ë””ì˜¤ ì „ì†¡
         const formData = new FormData();
         formData.append('audio', Buffer.from(audioData), {
           filename: 'chunk.webm',
           contentType: 'audio/webm'
         });

         const sttResponse = await axios.post(
           `${AI_SERVICE_URL}/api/stt/transcribe`,
           formData,
           {
             headers: formData.getHeaders()
           }
         );

         const transcript = sttResponse.data;

         // ì „ì‚¬ ê²°ê³¼ë¥¼ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡
         io.to(`meeting-${meetingId}`).emit('transcription', {
           id: Date.now().toString(),
           text: transcript.text,
           timestamp: new Date().toISOString(),
           latency: transcript.latency
         });

         // ì „ì‚¬ê°€ ì¼ì • ê¸¸ì´ ì´ìƒì´ë©´ ì§ˆë¬¸ ìƒì„±
         if (transcript.text.length > 100) {
           const questionResponse = await axios.post(
             `${AI_SERVICE_URL}/api/questions/generate`,
             { transcript: transcript.text }
           );

           const questions = questionResponse.data.questions;

           // ì§ˆë¬¸ë“¤ì„ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡
           questions.forEach((question: any) => {
             io.to(`meeting-${meetingId}`).emit('question_suggested', {
               id: Date.now().toString() + Math.random(),
               ...question,
               timestamp: new Date().toISOString()
             });
           });
         }

       } catch (error) {
         console.error('Audio processing error:', error);
         socket.emit('error', {
           type: 'audio_processing',
           message: 'Failed to process audio'
         });
       }
     });

     socket.on('leave_meeting', (data) => {
       const { meetingId, userId } = data;
       socket.leave(`meeting-${meetingId}`);
       console.log(`User ${userId} left meeting ${meetingId}`);

       socket.to(`meeting-${meetingId}`).emit('participant_left', {
         userId,
         timestamp: new Date().toISOString()
       });
     });

     socket.on('disconnect', () => {
       console.log('Client disconnected:', socket.id);
     });
   });

   const PORT = process.env.PORT || 3000;
   httpServer.listen(PORT, () => {
     console.log(`Server running on http://localhost:${PORT}`);
   });
   ```

2. **package.json scripts ì¶”ê°€**
   ```json
   {
     "scripts": {
       "dev": "nodemon --exec ts-node src/server.ts",
       "build": "tsc",
       "start": "node dist/server.js"
     }
   }
   ```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] WebSocket ì„œë²„ êµ¬í˜„
- [ ] AI Service ì—°ë™
- [ ] ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ êµ¬í˜„ (join_meeting, audio_chunk, leave_meeting)
- [ ] ì—ëŸ¬ í•¸ë“¤ë§
- [ ] ë¡œê¹…
- [ ] ì„œë²„ ì‹¤í–‰ í™•ì¸

**ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„

---

#### Task 1.4.2: Frontend WebSocket í´ë¼ì´ì–¸íŠ¸

**ì‘ì—… ë‚´ìš©**:

1. **WebSocket Service**
   ```typescript
   // frontend/src/services/websocket.ts
   import { io, Socket } from 'socket.io-client';
   import { useMeetingStore } from '../stores/meetingStore';

   class WebSocketService {
     private socket: Socket | null = null;
     private meetingId: string | null = null;

     connect(wsUrl: string) {
       this.socket = io(wsUrl);

       this.socket.on('connect', () => {
         console.log('Connected to WebSocket server');
       });

       this.socket.on('transcription', (data) => {
         console.log('Transcription received:', data);
         useMeetingStore.getState().addTranscript(data);
       });

       this.socket.on('question_suggested', (data) => {
         console.log('Question suggested:', data);
         useMeetingStore.getState().addQuestion(data);
       });

       this.socket.on('participant_joined', (data) => {
         console.log('Participant joined:', data);
       });

       this.socket.on('participant_left', (data) => {
         console.log('Participant left:', data);
       });

       this.socket.on('error', (data) => {
         console.error('WebSocket error:', data);
       });

       this.socket.on('disconnect', () => {
         console.log('Disconnected from WebSocket server');
       });
     }

     joinMeeting(meetingId: string, userId: string) {
       this.meetingId = meetingId;
       this.socket?.emit('join_meeting', { meetingId, userId });
     }

     sendAudioChunk(audioData: Blob) {
       if (!this.meetingId) {
         console.error('No meeting joined');
         return;
       }

       const reader = new FileReader();
       reader.onload = () => {
         this.socket?.emit('audio_chunk', {
           meetingId: this.meetingId,
           audioData: reader.result
         });
       };
       reader.readAsArrayBuffer(audioData);
     }

     leaveMeeting(userId: string) {
       if (!this.meetingId) return;

       this.socket?.emit('leave_meeting', {
         meetingId: this.meetingId,
         userId
       });
       this.meetingId = null;
     }

     disconnect() {
       this.socket?.disconnect();
     }
   }

   export default new WebSocketService();
   ```

2. **Zustand Store**
   ```typescript
   // frontend/src/stores/meetingStore.ts
   import { create } from 'zustand';

   interface Transcript {
     id: string;
     text: string;
     timestamp: string;
     latency?: number;
   }

   interface Question {
     id: string;
     text: string;
     priority: 'critical' | 'important' | 'follow_up';
     reason: string;
     category: string;
     timestamp: string;
     action?: 'used' | 'ignored' | 'dismissed';
   }

   interface MeetingStore {
     transcripts: Transcript[];
     questions: Question[];
     isRecording: boolean;

     addTranscript: (transcript: Transcript) => void;
     addQuestion: (question: Question) => void;
     updateQuestionAction: (questionId: string, action: string) => void;
     setRecording: (isRecording: boolean) => void;
     reset: () => void;
   }

   export const useMeetingStore = create<MeetingStore>((set) => ({
     transcripts: [],
     questions: [],
     isRecording: false,

     addTranscript: (transcript) =>
       set((state) => ({
         transcripts: [...state.transcripts, transcript]
       })),

     addQuestion: (question) =>
       set((state) => ({
         questions: [...state.questions, question]
       })),

     updateQuestionAction: (questionId, action) =>
       set((state) => ({
         questions: state.questions.map((q) =>
           q.id === questionId ? { ...q, action } : q
         )
       })),

     setRecording: (isRecording) => set({ isRecording }),

     reset: () => set({ transcripts: [], questions: [], isRecording: false })
   }));
   ```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] WebSocket Service êµ¬í˜„
- [ ] Zustand Store êµ¬í˜„
- [ ] ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ êµ¬í˜„
- [ ] ìƒíƒœ ê´€ë¦¬ ë¡œì§ êµ¬í˜„

**ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„

---

### Phase 1-5: UI ì»´í¬ë„ŒíŠ¸ êµ¬í˜„ (Day 8-9)

**ì˜ˆìƒ ì†Œìš”**: 2ì¼
**ìš°ì„ ìˆœìœ„**: ğŸ”¥ Critical

#### Task 1.5.1: AudioRecorder ì»´í¬ë„ŒíŠ¸

**ì‘ì—… ë‚´ìš©**:

```typescript
// frontend/src/components/AudioRecorder.tsx
import { useState, useRef, useEffect } from 'react';
import { useMeetingStore } from '../stores/meetingStore';

interface AudioRecorderProps {
  onAudioChunk: (blob: Blob) => void;
}

export function AudioRecorder({ onAudioChunk }: AudioRecorderProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const streamRef = useRef<MediaStream | null>(null);

  const { setRecording } = useMeetingStore();

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: 'audio/webm'
      });

      mediaRecorder.ondataavailable = (e) => {
        if (e.data.size > 0) {
          onAudioChunk(e.data);
        }
      };

      mediaRecorder.onerror = (e) => {
        console.error('MediaRecorder error:', e);
        setError('ë…¹ìŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.');
      };

      // 5ì´ˆë§ˆë‹¤ chunk ì „ì†¡
      mediaRecorder.start(5000);
      mediaRecorderRef.current = mediaRecorder;
      setIsRecording(true);
      setRecording(true);
      setError(null);

    } catch (err) {
      console.error('Failed to start recording:', err);
      setError('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.');
    }
  };

  const stopRecording = () => {
    if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') {
      mediaRecorderRef.current.stop();
    }

    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
    }

    setIsRecording(false);
    setRecording(false);
  };

  useEffect(() => {
    return () => {
      // Cleanup on unmount
      stopRecording();
    };
  }, []);

  return (
    <div className="audio-recorder">
      <button
        onClick={isRecording ? stopRecording : startRecording}
        className={`record-button ${isRecording ? 'recording' : ''}`}
      >
        {isRecording ? 'â¹ï¸ ì •ì§€' : 'ğŸ¤ ë…¹ìŒ ì‹œì‘'}
      </button>

      {isRecording && (
        <div className="recording-indicator">
          <span className="pulse"></span>
          ë…¹ìŒ ì¤‘...
        </div>
      )}

      {error && (
        <div className="error-message">
          âš ï¸ {error}
        </div>
      )}
    </div>
  );
}
```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] ì»´í¬ë„ŒíŠ¸ êµ¬í˜„
- [ ] ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
- [ ] ë…¹ìŒ ì‹œì‘/ì •ì§€
- [ ] 5ì´ˆë§ˆë‹¤ chunk ì „ì†¡
- [ ] ì—ëŸ¬ í•¸ë“¤ë§
- [ ] UI í”¼ë“œë°± (ë…¹ìŒ ì¤‘ í‘œì‹œ)

**ì˜ˆìƒ ì‹œê°„**: 2ì‹œê°„

---

#### Task 1.5.2: TranscriptPanel & QuestionCard ì»´í¬ë„ŒíŠ¸

**ì‘ì—… ë‚´ìš©**:

1. **TranscriptPanel**
   ```typescript
   // frontend/src/components/TranscriptPanel.tsx
   import { useMeetingStore } from '../stores/meetingStore';

   export function TranscriptPanel() {
     const { transcripts } = useMeetingStore();

     return (
       <div className="transcript-panel">
         <h3>ğŸ“ ëŒ€í™” ë‚´ìš©</h3>
         <div className="transcript-list">
           {transcripts.length === 0 && (
             <p className="empty-state">ëŒ€í™”ê°€ ì „ì‚¬ë˜ë©´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</p>
           )}
           {transcripts.map((t) => (
             <div key={t.id} className="transcript-item">
               <p className="transcript-text">{t.text}</p>
               <span className="transcript-time">
                 {new Date(t.timestamp).toLocaleTimeString()}
                 {t.latency && ` (${t.latency.toFixed(2)}s)`}
               </span>
             </div>
           ))}
         </div>
       </div>
     );
   }
   ```

2. **QuestionCard**
   ```typescript
   // frontend/src/components/QuestionCard.tsx
   import { useMeetingStore } from '../stores/meetingStore';

   interface QuestionCardProps {
     question: {
       id: string;
       text: string;
       priority: 'critical' | 'important' | 'follow_up';
       reason: string;
       category: string;
       action?: string;
     };
   }

   const PRIORITY_LABELS = {
     critical: 'ğŸ”¥ í•„ìˆ˜',
     important: 'â­ ì¤‘ìš”',
     follow_up: 'ğŸ’¬ í›„ì†'
   };

   const PRIORITY_COLORS = {
     critical: '#ff4444',
     important: '#ff9944',
     follow_up: '#4499ff'
   };

   export function QuestionCard({ question }: QuestionCardProps) {
     const { updateQuestionAction } = useMeetingStore();

     const handleUse = () => {
       updateQuestionAction(question.id, 'used');
     };

     const handleDismiss = () => {
       updateQuestionAction(question.id, 'dismissed');
     };

     if (question.action === 'dismissed') {
       return null; // ìˆ¨ê¹€
     }

     return (
       <div
         className={`question-card ${question.action || ''}`}
         style={{ borderLeftColor: PRIORITY_COLORS[question.priority] }}
       >
         <div className="question-header">
           <span
             className="priority-badge"
             style={{ backgroundColor: PRIORITY_COLORS[question.priority] }}
           >
             {PRIORITY_LABELS[question.priority]}
           </span>
           <span className="category-badge">{question.category}</span>
         </div>

         <p className="question-text">{question.text}</p>
         <p className="question-reason">ğŸ’¡ {question.reason}</p>

         <div className="question-actions">
           <button onClick={handleUse} className="btn-use">
             âœ… ì‚¬ìš©
           </button>
           <button onClick={handleDismiss} className="btn-dismiss">
             âŒ ë¬´ì‹œ
           </button>
         </div>
       </div>
     );
   }
   ```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] TranscriptPanel êµ¬í˜„
- [ ] QuestionCard êµ¬í˜„
- [ ] Priority í‘œì‹œ
- [ ] Category í‘œì‹œ
- [ ] ì•¡ì…˜ ë²„íŠ¼ (ì‚¬ìš©/ë¬´ì‹œ)
- [ ] ë¹ˆ ìƒíƒœ ì²˜ë¦¬

**ì˜ˆìƒ ì‹œê°„**: 2-3ì‹œê°„

---

#### Task 1.5.3: MeetingRoom í†µí•© í™”ë©´

**ì‘ì—… ë‚´ìš©**:

```typescript
// frontend/src/components/MeetingRoom.tsx
import { useEffect } from 'react';
import { AudioRecorder } from './AudioRecorder';
import { TranscriptPanel } from './TranscriptPanel';
import { QuestionCard } from './QuestionCard';
import { useMeetingStore } from '../stores/meetingStore';
import websocketService from '../services/websocket';

export function MeetingRoom() {
  const { questions, isRecording, reset } = useMeetingStore();

  const WS_URL = import.meta.env.VITE_WS_URL || 'http://localhost:3000';
  const MEETING_ID = 'prototype-meeting-1';
  const USER_ID = 'user-1';

  useEffect(() => {
    // WebSocket ì—°ê²°
    websocketService.connect(WS_URL);
    websocketService.joinMeeting(MEETING_ID, USER_ID);

    return () => {
      websocketService.leaveMeeting(USER_ID);
      websocketService.disconnect();
      reset();
    };
  }, []);

  const handleAudioChunk = (blob: Blob) => {
    websocketService.sendAudioChunk(blob);
  };

  return (
    <div className="meeting-room">
      <header className="meeting-header">
        <h1>ğŸ¯ Onno í”„ë¡œí† íƒ€ì…</h1>
        <div className="meeting-status">
          {isRecording ? (
            <span className="status-recording">ğŸ”´ ë…¹ìŒ ì¤‘</span>
          ) : (
            <span className="status-idle">âšª ëŒ€ê¸° ì¤‘</span>
          )}
        </div>
      </header>

      <div className="meeting-controls">
        <AudioRecorder onAudioChunk={handleAudioChunk} />
      </div>

      <div className="meeting-content">
        <div className="left-panel">
          <TranscriptPanel />
        </div>

        <div className="right-panel">
          <div className="questions-section">
            <h3>ğŸ’¡ AI ì§ˆë¬¸ ì œì•ˆ</h3>
            <div className="questions-list">
              {questions.length === 0 && (
                <p className="empty-state">
                  ëŒ€í™”ê°€ ì§„í–‰ë˜ë©´ AIê°€ ì§ˆë¬¸ì„ ì œì•ˆí•©ë‹ˆë‹¤.
                </p>
              )}
              {questions
                .filter((q) => q.action !== 'dismissed')
                .map((q) => (
                  <QuestionCard key={q.id} question={q} />
                ))}
            </div>
          </div>
        </div>
      </div>
    </div>
  );
}
```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] MeetingRoom ì»´í¬ë„ŒíŠ¸ êµ¬í˜„
- [ ] WebSocket ì—°ê²° ê´€ë¦¬
- [ ] ì»´í¬ë„ŒíŠ¸ í†µí•©
- [ ] ë ˆì´ì•„ì›ƒ êµ¬ì„±

**ì˜ˆìƒ ì‹œê°„**: 1-2ì‹œê°„

---

#### Task 1.5.4: ê¸°ë³¸ ìŠ¤íƒ€ì¼ë§

**ì‘ì—… ë‚´ìš©**:

```css
/* frontend/src/App.css */

* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
  background: #f5f5f5;
}

.meeting-room {
  max-width: 1400px;
  margin: 0 auto;
  padding: 20px;
}

.meeting-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 30px;
}

.meeting-header h1 {
  font-size: 32px;
  color: #333;
}

.meeting-status {
  font-size: 18px;
}

.status-recording {
  color: #ff4444;
  font-weight: bold;
}

.status-idle {
  color: #999;
}

.meeting-controls {
  margin-bottom: 30px;
  text-align: center;
}

.audio-recorder {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 15px;
}

.record-button {
  padding: 20px 40px;
  font-size: 20px;
  border: none;
  border-radius: 50px;
  background: #4CAF50;
  color: white;
  cursor: pointer;
  transition: all 0.3s;
  box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
}

.record-button:hover {
  background: #45a049;
  transform: translateY(-2px);
  box-shadow: 0 6px 8px rgba(0, 0, 0, 0.15);
}

.record-button.recording {
  background: #ff4444;
  animation: pulse 2s infinite;
}

@keyframes pulse {
  0%, 100% { opacity: 1; }
  50% { opacity: 0.7; }
}

.recording-indicator {
  display: flex;
  align-items: center;
  gap: 10px;
  color: #ff4444;
  font-weight: bold;
}

.pulse {
  width: 12px;
  height: 12px;
  background: #ff4444;
  border-radius: 50%;
  animation: pulse-dot 1.5s infinite;
}

@keyframes pulse-dot {
  0%, 100% { transform: scale(1); opacity: 1; }
  50% { transform: scale(1.5); opacity: 0.5; }
}

.meeting-content {
  display: grid;
  grid-template-columns: 1fr 1fr;
  gap: 30px;
}

.left-panel, .right-panel {
  background: white;
  border-radius: 12px;
  padding: 25px;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.1);
}

.transcript-panel h3,
.questions-section h3 {
  margin-bottom: 20px;
  color: #333;
  font-size: 20px;
}

.transcript-list {
  max-height: 600px;
  overflow-y: auto;
}

.transcript-item {
  padding: 15px;
  margin-bottom: 10px;
  background: #f9f9f9;
  border-radius: 8px;
  border-left: 3px solid #4CAF50;
}

.transcript-text {
  margin-bottom: 8px;
  line-height: 1.5;
  color: #333;
}

.transcript-time {
  font-size: 12px;
  color: #999;
}

.questions-list {
  display: flex;
  flex-direction: column;
  gap: 15px;
}

.question-card {
  padding: 20px;
  background: #fff;
  border-radius: 8px;
  border-left: 4px solid;
  box-shadow: 0 2px 4px rgba(0, 0, 0, 0.1);
  transition: all 0.3s;
}

.question-card:hover {
  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.15);
  transform: translateY(-2px);
}

.question-card.used {
  opacity: 0.6;
  background: #f0f0f0;
}

.question-header {
  display: flex;
  gap: 10px;
  margin-bottom: 12px;
}

.priority-badge {
  padding: 4px 12px;
  border-radius: 12px;
  color: white;
  font-size: 12px;
  font-weight: bold;
}

.category-badge {
  padding: 4px 12px;
  border-radius: 12px;
  background: #e0e0e0;
  font-size: 12px;
  color: #666;
}

.question-text {
  font-size: 16px;
  font-weight: 600;
  color: #333;
  margin-bottom: 10px;
  line-height: 1.5;
}

.question-reason {
  font-size: 14px;
  color: #666;
  margin-bottom: 15px;
  line-height: 1.4;
}

.question-actions {
  display: flex;
  gap: 10px;
}

.btn-use,
.btn-dismiss {
  padding: 8px 16px;
  border: none;
  border-radius: 6px;
  cursor: pointer;
  font-size: 14px;
  transition: all 0.2s;
}

.btn-use {
  background: #4CAF50;
  color: white;
}

.btn-use:hover {
  background: #45a049;
}

.btn-dismiss {
  background: #f5f5f5;
  color: #666;
}

.btn-dismiss:hover {
  background: #e0e0e0;
}

.empty-state {
  text-align: center;
  color: #999;
  padding: 40px;
  font-size: 14px;
}

.error-message {
  color: #ff4444;
  background: #ffe0e0;
  padding: 12px;
  border-radius: 6px;
  font-size: 14px;
}
```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] ê¸°ë³¸ ë ˆì´ì•„ì›ƒ ìŠ¤íƒ€ì¼
- [ ] ì»´í¬ë„ŒíŠ¸ë³„ ìŠ¤íƒ€ì¼
- [ ] ë°˜ì‘í˜• ë””ìì¸ (ì„ íƒ)
- [ ] ì• ë‹ˆë©”ì´ì…˜ íš¨ê³¼

**ì˜ˆìƒ ì‹œê°„**: 2ì‹œê°„

---

### Phase 1-6: End-to-End í…ŒìŠ¤íŠ¸ (Day 10)

**ì˜ˆìƒ ì†Œìš”**: 1ì¼
**ìš°ì„ ìˆœìœ„**: ğŸ”¥ Critical

#### Task 1.6.1: í†µí•© í…ŒìŠ¤íŠ¸

**ì‘ì—… ë‚´ìš©**:

1. **3ê°œ ì„œë²„ ë™ì‹œ ì‹¤í–‰**
   ```bash
   # Terminal 1: AI Service
   cd ai-service
   source venv/bin/activate
   uvicorn app.main:app --reload --port 8000

   # Terminal 2: Backend
   cd backend
   npm run dev

   # Terminal 3: Frontend
   cd frontend
   npm run dev
   ```

2. **í…ŒìŠ¤íŠ¸ ì²´í¬ë¦¬ìŠ¤íŠ¸**
   - [ ] Frontend ì ‘ì† (http://localhost:5173)
   - [ ] ë…¹ìŒ ì‹œì‘ ë²„íŠ¼ í´ë¦­
   - [ ] ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©
   - [ ] í•œêµ­ì–´ë¡œ ë§í•˜ê¸° (1-2ë¶„)
   - [ ] ì „ì‚¬ ê²°ê³¼ê°€ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë˜ëŠ”ì§€ í™•ì¸
   - [ ] AI ì§ˆë¬¸ì´ ìë™ìœ¼ë¡œ ìƒì„±ë˜ëŠ”ì§€ í™•ì¸
   - [ ] ì§ˆë¬¸ ì¹´ë“œ ì•¡ì…˜ (ì‚¬ìš©/ë¬´ì‹œ) ë™ì‘ í™•ì¸
   - [ ] ë…¹ìŒ ì •ì§€
   - [ ] ì—ëŸ¬ ì—†ì´ ì¢…ë£Œë˜ëŠ”ì§€ í™•ì¸

3. **ì„±ëŠ¥ ì¸¡ì •**
   - [ ] ìŒì„± â†’ ì „ì‚¬ Latency ì¸¡ì • (ëª©í‘œ: <2ì´ˆ)
   - [ ] ì „ì‚¬ â†’ ì§ˆë¬¸ Latency ì¸¡ì • (ëª©í‘œ: <1ì´ˆ)
   - [ ] Total End-to-End Latency (ëª©í‘œ: <5ì´ˆ)
   - [ ] STT ì •í™•ë„ í™•ì¸ (ëª©í‘œ: 90%+)

4. **ë¬¸ì œì  ê¸°ë¡**
   ```markdown
   # ë°œê²¬ëœ ë¬¸ì œì 

   ## P0 (ì¹˜ëª…ì )
   - [ ] ë¬¸ì œ 1: ...
   - [ ] ë¬¸ì œ 2: ...

   ## P1 (ì¤‘ìš”)
   - [ ] ë¬¸ì œ 1: ...
   - [ ] ë¬¸ì œ 2: ...

   ## P2 (ê°œì„ )
   - [ ] ë¬¸ì œ 1: ...
   - [ ] ë¬¸ì œ 2: ...
   ```

**ì™„ë£Œ ì¡°ê±´**:
- [ ] ì „ì²´ íŒŒì´í”„ë¼ì¸ ë™ì‘ í™•ì¸
- [ ] ì„±ëŠ¥ ì§€í‘œ ì¸¡ì • ë° ê¸°ë¡
- [ ] ë¬¸ì œì  ëª©ë¡ ì‘ì„±
- [ ] í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¬¸ì„œí™” (`docs/test-results/iteration-1-e2e.md`)

**ì˜ˆìƒ ì‹œê°„**: 3-4ì‹œê°„

---

#### Task 1.6.2: ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘

**ì‘ì—… ë‚´ìš©**:

1. **í”¼ë“œë°± ì§ˆë¬¸ì§€**
   ```markdown
   # Onno í”„ë¡œí† íƒ€ì… í”¼ë“œë°±

   ## 1. ì „ë°˜ì ì¸ ê²½í—˜
   - ì „ì²´ì ì¸ ì¸ìƒì€ ì–´ë• ë‚˜ìš”? (1-5)
   - ê°€ì¥ ì¢‹ì•˜ë˜ ì ì€?
   - ê°€ì¥ ê°œì„ ì´ í•„ìš”í•œ ì ì€?

   ## 2. ì‹¤ì‹œê°„ ì „ì‚¬ (STT)
   - ì „ì‚¬ ì •í™•ë„ëŠ” ì–´ë• ë‚˜ìš”? (1-5)
   - ì „ì‚¬ ì†ë„ëŠ” ë§Œì¡±ìŠ¤ëŸ¬ì› ë‚˜ìš”? (1-5)
   - ê°œì„  ì˜ê²¬:

   ## 3. AI ì§ˆë¬¸ ì œì•ˆ
   - ì§ˆë¬¸ì´ ì ì ˆí–ˆë‚˜ìš”? (1-5)
   - ì§ˆë¬¸ì´ ì‹¤ì œë¡œ ë„ì›€ì´ ë  ê²ƒ ê°™ë‚˜ìš”? (1-5)
   - ì§ˆë¬¸ì˜ íƒ€ì´ë°ì€ ì ì ˆí–ˆë‚˜ìš”? (1-5)
   - ê°œì„  ì˜ê²¬:

   ## 4. ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤
   - UIê°€ ì§ê´€ì ì´ì—ˆë‚˜ìš”? (1-5)
   - ì‹¤ì‹œê°„ ëŠë‚Œì´ ì „ë‹¬ë˜ì—ˆë‚˜ìš”? (1-5)
   - ê°œì„  ì˜ê²¬:

   ## 5. ê¸°íƒ€
   - ì¶”ê°€í•˜ê³  ì‹¶ì€ ê¸°ëŠ¥:
   - ì „ì²´ ì½”ë©˜íŠ¸:
   ```

2. **í”¼ë“œë°± ìˆ˜ì§‘**
   - [ ] ë³¸ì¸ í…ŒìŠ¤íŠ¸ ë° í”¼ë“œë°± ì‘ì„±
   - [ ] 1-2ëª… ì¶”ê°€ í…ŒìŠ¤í„° ì„­ì™¸ (ì„ íƒ)
   - [ ] í”¼ë“œë°± ì·¨í•© ë° ë¶„ì„

**ì™„ë£Œ ì¡°ê±´**:
- [ ] í”¼ë“œë°± ì§ˆë¬¸ì§€ ì¤€ë¹„
- [ ] ìµœì†Œ 1ëª… (ë³¸ì¸) í”¼ë“œë°± ìˆ˜ì§‘
- [ ] í”¼ë“œë°± ë¶„ì„ ë° ë¬¸ì„œí™”

**ì˜ˆìƒ ì‹œê°„**: 2ì‹œê°„

---

## ğŸ“Š Iteration 1 ì„±ê³µ ì§€í‘œ (ì¬í™•ì¸)

### í•„ìˆ˜ (Must-have)
- [ ] STT ì •í™•ë„ 90%+
- [ ] End-to-End Latency < 5ì´ˆ
- [ ] AI ì§ˆë¬¸ 3ê°œ ì´ìƒ ìƒì„± (3ë¶„ íšŒì˜ ê¸°ì¤€)
- [ ] ì‹¤ì‹œê°„ UI ì—…ë°ì´íŠ¸ ë™ì‘

### ëª©í‘œ (Should-have)
- [ ] STT ì •í™•ë„ 95%+
- [ ] Latency < 3ì´ˆ
- [ ] ì§ˆë¬¸ í’ˆì§ˆ í‰ê°€ 4.0+/5.0
- [ ] ì‚¬ìš©ì í”¼ë“œë°± ìˆ˜ì§‘ ì™„ë£Œ

---

## ğŸ“ ì‚°ì¶œë¬¼ (Deliverables)

### ì½”ë“œ
- [ ] `frontend/` - React í”„ë¡œí† íƒ€ì… ì•±
- [ ] `backend/` - Node.js WebSocket ì„œë²„
- [ ] `ai-service/` - Python FastAPI AI ì„œë¹„ìŠ¤

### ë¬¸ì„œ
- [ ] `docs/test-results/iteration-1-stt.md` - STT í…ŒìŠ¤íŠ¸ ê²°ê³¼
- [ ] `docs/test-results/iteration-1-questions.md` - AI ì§ˆë¬¸ í…ŒìŠ¤íŠ¸ ê²°ê³¼
- [ ] `docs/test-results/iteration-1-e2e.md` - End-to-End í…ŒìŠ¤íŠ¸ ê²°ê³¼
- [ ] `docs/test-results/iteration-1-feedback.md` - ì‚¬ìš©ì í”¼ë“œë°±

### ê¸°íƒ€
- [ ] í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ìƒ˜í”Œ (3ê°œ)
- [ ] ìŠ¤í¬ë¦°ìƒ· ë˜ëŠ” ë°ëª¨ ì˜ìƒ (ì„ íƒ)

---

## â±ï¸ ì¼ì • ìš”ì•½

| Day | Phase | ì‘ì—… ë‚´ìš© | ì˜ˆìƒ ì‹œê°„ |
|-----|-------|----------|----------|
| 1-2 | 1-1 | í”„ë¡œì íŠ¸ ì´ˆê¸°í™” | 4-5ì‹œê°„ |
| 3-4 | 1-2 | STT ì„œë¹„ìŠ¤ êµ¬í˜„ | 6-8ì‹œê°„ |
| 4-5 | 1-3 | AI ì§ˆë¬¸ ìƒì„± | 4-6ì‹œê°„ |
| 6-7 | 1-4 | WebSocket íŒŒì´í”„ë¼ì¸ | 5-7ì‹œê°„ |
| 8-9 | 1-5 | UI ì»´í¬ë„ŒíŠ¸ | 7-9ì‹œê°„ |
| 10 | 1-6 | E2E í…ŒìŠ¤íŠ¸ & í”¼ë“œë°± | 5-6ì‹œê°„ |
| **Total** | | | **31-41ì‹œê°„** |

**ì‹¤ì œ ë‹¬ë ¥ ê¸°ê°„**: 7-10ì¼ (1ì¼ 4-6ì‹œê°„ ì‘ì—… ê°€ì •)

---

## ğŸš€ ë‹¤ìŒ Iteration ê³„íš (Preview)

Iteration 1 ì™„ë£Œ í›„, ê²°ê³¼ì— ë”°ë¼ ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒ:

### Option A: í”„ë¡œí† íƒ€ì… ì™„ì„±ë„ ë†’ì´ê¸°
- ê°œì¸í™” ì‹œìŠ¤í…œ Lv.1 ì¶”ê°€
- íšŒì˜ íˆìŠ¤í† ë¦¬ ì €ì¥ (LocalStorage)
- UI/UX ê°œì„ 

### Option B: í™•ì¥ ê¸°ëŠ¥ ì¶”ê°€
- ê´€ê³„ ê°ì²´ ì‹œìŠ¤í…œ í”„ë¡œí† íƒ€ì…
- Notion ì—°ë™
- í˜ë¥´ì†Œë‚˜ ì„ íƒ

### Option C: MVPë¡œ ë°œì „
- DB ì—°ë™ (PostgreSQL + Prisma)
- ì‚¬ìš©ì ì¸ì¦
- ë°°í¬ ì¤€ë¹„ (Vercel + Railway)

---

## ğŸ“ Daily Log (ì‘ì—… ì§„í–‰ ì¤‘ ì—…ë°ì´íŠ¸)

### Day 1 (2025-12-02)
- [ ] Task 1.1.1: í”„ë¡œì íŠ¸ êµ¬ì¡° ìƒì„±
- [ ] Task 1.1.2: í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
- [ ] Task 1.1.3: ê¸°ë³¸ ì„œë²„ êµ¬ë™ í™•ì¸

### Day 2
- [ ] ...

### Day 3
- [ ] ...

---

**ì‘ì„±ì**: ë°•ì¤€í™ + Claude
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-12-02
